{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-13T12:13:53.124197Z",
     "iopub.status.busy": "2023-05-13T12:13:53.123330Z",
     "iopub.status.idle": "2023-05-13T12:13:53.144407Z",
     "shell.execute_reply": "2023-05-13T12:13:53.143444Z",
     "shell.execute_reply.started": "2023-05-13T12:13:53.124161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fake-reviews/fake_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:13:58.185130Z",
     "iopub.status.busy": "2023-05-13T12:13:58.184788Z",
     "iopub.status.idle": "2023-05-13T12:14:09.421149Z",
     "shell.execute_reply": "2023-05-13T12:14:09.420229Z",
     "shell.execute_reply.started": "2023-05-13T12:13:58.185104Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tokenizers\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:14:26.584031Z",
     "iopub.status.busy": "2023-05-13T12:14:26.582716Z",
     "iopub.status.idle": "2023-05-13T12:14:26.605271Z",
     "shell.execute_reply": "2023-05-13T12:14:26.603572Z",
     "shell.execute_reply.started": "2023-05-13T12:14:26.583995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of replicas: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy (you can see that it is pretty easy to set up).\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set (always set in Kaggle)\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-12T20:35:00.857202Z",
     "iopub.status.busy": "2023-05-12T20:35:00.856146Z",
     "iopub.status.idle": "2023-05-12T20:35:00.862903Z",
     "shell.execute_reply": "2023-05-12T20:35:00.861819Z",
     "shell.execute_reply.started": "2023-05-12T20:35:00.857139Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'roberta-base'\n",
    "MAX_LEN = 256\n",
    "ARTIFACTS_PATH = '../artifacts/'\n",
    "\n",
    "BATCH_SIZE = 8 * strategy.num_replicas_in_sync\n",
    "EPOCHS = 3\n",
    "\n",
    "if not os.path.exists(ARTIFACTS_PATH):\n",
    "    os.makedirs(ARTIFACTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:14:31.457165Z",
     "iopub.status.busy": "2023-05-13T12:14:31.456810Z",
     "iopub.status.idle": "2023-05-13T12:14:32.776566Z",
     "shell.execute_reply": "2023-05-13T12:14:32.775527Z",
     "shell.execute_reply.started": "2023-05-13T12:14:31.457137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>fake_review</th>\n",
       "      <th>cleaned_review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★</td>\n",
       "      <td>These Really Do Work Great, But You Do Need To...</td>\n",
       "      <td>0</td>\n",
       "      <td>work great need know thing year paid dollar pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Favorite for winter. Very warm!</td>\n",
       "      <td>I love this dress. Absolute favorite for winte...</td>\n",
       "      <td>0</td>\n",
       "      <td>love dress absolute favorite winter heavy mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great Socks for the money.</td>\n",
       "      <td>Nice socks, great colors, just enough support ...</td>\n",
       "      <td>0</td>\n",
       "      <td>nice sock great color support wearing good pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slick hat!</td>\n",
       "      <td>I bought this for my husband and WOW, this is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>bought husband slick high quality craftsmanshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would do it again!</td>\n",
       "      <td>Perfect dress and the customer service was awe...</td>\n",
       "      <td>0</td>\n",
       "      <td>perfect dress customer service awesomei</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     review_headline  \\\n",
       "0  ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKING ★   \n",
       "1                    Favorite for winter. Very warm!   \n",
       "2                         Great Socks for the money.   \n",
       "3                                         Slick hat!   \n",
       "4                               I would do it again!   \n",
       "\n",
       "                                         review_body  fake_review  \\\n",
       "0  These Really Do Work Great, But You Do Need To...            0   \n",
       "1  I love this dress. Absolute favorite for winte...            0   \n",
       "2  Nice socks, great colors, just enough support ...            0   \n",
       "3  I bought this for my husband and WOW, this is ...            0   \n",
       "4  Perfect dress and the customer service was awe...            0   \n",
       "\n",
       "                                 cleaned_review_body  \n",
       "0  work great need know thing year paid dollar pr...  \n",
       "1  love dress absolute favorite winter heavy mate...  \n",
       "2  nice sock great color support wearing good pai...  \n",
       "3  bought husband slick high quality craftsmanshi...  \n",
       "4            perfect dress customer service awesomei  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/fake-reviews/fake_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:14:36.306849Z",
     "iopub.status.busy": "2023-05-13T12:14:36.306432Z",
     "iopub.status.idle": "2023-05-13T12:14:49.874840Z",
     "shell.execute_reply": "2023-05-13T12:14:49.873587Z",
     "shell.execute_reply.started": "2023-05-13T12:14:36.306818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neattext\n",
      "  Downloading neattext-0.1.3-py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.7/114.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: neattext\n",
      "Successfully installed neattext-0.1.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install neattext\n",
    "import neattext as nt\n",
    "def text_preprocessing(text):\n",
    "  text=nt.fix_contractions(text)     #I'm -> I am\n",
    "  text=nt.remove_urls(text)          #removing urls\n",
    "  text=nt.remove_non_ascii(text)     #removing non-ascii characters\n",
    "  text=nt.remove_numbers(text)       #removing numbers\n",
    "  text=nt.remove_multiple_spaces(text)  #removing multiple spaces\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:14:53.825469Z",
     "iopub.status.busy": "2023-05-13T12:14:53.824900Z",
     "iopub.status.idle": "2023-05-13T12:15:27.952302Z",
     "shell.execute_reply": "2023-05-13T12:15:27.951350Z",
     "shell.execute_reply.started": "2023-05-13T12:14:53.825426Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cleaned_review_body']=df.review_body.apply(lambda x:text_preprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:15:37.924867Z",
     "iopub.status.busy": "2023-05-13T12:15:37.924441Z",
     "iopub.status.idle": "2023-05-13T12:15:37.931149Z",
     "shell.execute_reply": "2023-05-13T12:15:37.930212Z",
     "shell.execute_reply.started": "2023-05-13T12:15:37.924834Z"
    }
   },
   "outputs": [],
   "source": [
    "def postprocessing(text):\n",
    "  text=nt.remove_stopwords(text)\n",
    "  text=nt.remove_special_characters(text)\n",
    "  text=nt.remove_emojis(text)\n",
    "  text=nt.remove_shortwords(text,3)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:15:45.783232Z",
     "iopub.status.busy": "2023-05-13T12:15:45.782872Z",
     "iopub.status.idle": "2023-05-13T12:15:51.641732Z",
     "shell.execute_reply": "2023-05-13T12:15:51.640676Z",
     "shell.execute_reply.started": "2023-05-13T12:15:45.783205Z"
    }
   },
   "outputs": [],
   "source": [
    "df['cleaned_review_body']=df['cleaned_review_body'].apply(lambda x:postprocessing(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:25.501473Z",
     "iopub.status.busy": "2023-05-13T12:17:25.500752Z",
     "iopub.status.idle": "2023-05-13T12:17:25.736116Z",
     "shell.execute_reply": "2023-05-13T12:17:25.735177Z",
     "shell.execute_reply.started": "2023-05-13T12:17:25.501437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature  Missing Data\n",
      "\n",
      "review_headline         2\n",
      "review_body            36\n",
      "fake_review             0\n",
      "cleaned_review_body     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Feature ',end=' ')\n",
    "if(any(df.isnull().any())):\n",
    "    print('Missing Data\\n')\n",
    "    print(df.isnull().sum())\n",
    "else:\n",
    "    print('NO missing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:29.767674Z",
     "iopub.status.busy": "2023-05-13T12:17:29.767291Z",
     "iopub.status.idle": "2023-05-13T12:17:30.150166Z",
     "shell.execute_reply": "2023-05-13T12:17:30.149085Z",
     "shell.execute_reply.started": "2023-05-13T12:17:29.767643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130000 entries, 0 to 129999\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   review_headline      130000 non-null  object\n",
      " 1   review_body          130000 non-null  object\n",
      " 2   fake_review          130000 non-null  int64 \n",
      " 3   cleaned_review_body  130000 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df['review_headline'] = df['review_headline'].fillna(df['review_headline'].mode()[0]) # Mode- 'Reuters'\n",
    "df['review_body'] = df['review_body'].fillna(df['review_body'].mode()[0])\n",
    "df['cleaned_review_body'] = df['cleaned_review_body'].fillna(df['cleaned_review_body'].mode()[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:36.236901Z",
     "iopub.status.busy": "2023-05-13T12:17:36.236415Z",
     "iopub.status.idle": "2023-05-13T12:17:37.131671Z",
     "shell.execute_reply": "2023-05-13T12:17:37.130503Z",
     "shell.execute_reply.started": "2023-05-13T12:17:36.236869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size (130000, 4)\n",
      "Duplicate rows found\n",
      "Number of duplicate rows=  11366\n",
      "Dropping duplicates\n",
      "\n",
      "(118634, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Data Size {}'.format(df.shape))\n",
    "if(any(df.duplicated())==True):\n",
    "    print('Duplicate rows found')\n",
    "    print('Number of duplicate rows= ',df[df.duplicated()].shape[0])\n",
    "    df.drop_duplicates(inplace=True,keep='first')\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    print('Dropping duplicates\\n')\n",
    "    print(df.shape)\n",
    "else:\n",
    "    print('NO duplicate data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:41.941264Z",
     "iopub.status.busy": "2023-05-13T12:17:41.940883Z",
     "iopub.status.idle": "2023-05-13T12:17:41.959807Z",
     "shell.execute_reply": "2023-05-13T12:17:41.958762Z",
     "shell.execute_reply.started": "2023-05-13T12:17:41.941236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_review</th>\n",
       "      <th>cleaned_review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>work great need know things years first paid d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>love dress absolute favorite winter heavy mate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>nice socks great colors support wearing good p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>bought husband slick high quality craftsmanshi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>perfect dress customer service awesomei again</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fake_review                                cleaned_review_body\n",
       "0            0  work great need know things years first paid d...\n",
       "1            0  love dress absolute favorite winter heavy mate...\n",
       "2            0  nice socks great colors support wearing good p...\n",
       "3            0  bought husband slick high quality craftsmanshi...\n",
       "4            0      perfect dress customer service awesomei again"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['review_headline','review_body'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:45.771848Z",
     "iopub.status.busy": "2023-05-13T12:17:45.771350Z",
     "iopub.status.idle": "2023-05-13T12:17:45.784837Z",
     "shell.execute_reply": "2023-05-13T12:17:45.783678Z",
     "shell.execute_reply.started": "2023-05-13T12:17:45.771810Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 256\n",
    "def roberta_encode(texts, tokenizer):\n",
    "    ct = len(texts)\n",
    "    input_ids = np.ones((ct, MAX_LEN), dtype='int32')\n",
    "    attention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\n",
    "    token_type_ids = np.zeros((ct, MAX_LEN), dtype='int32') # Not used in text classification\n",
    "\n",
    "    for k, text in enumerate(texts):\n",
    "        # Tokenize\n",
    "        tok_text = tokenizer.tokenize(text)\n",
    "        \n",
    "        # Truncate and convert tokens to numerical IDs\n",
    "        enc_text = tokenizer.convert_tokens_to_ids(tok_text[:(MAX_LEN-2)])\n",
    "        \n",
    "        input_length = len(enc_text) + 2\n",
    "        input_length = input_length if input_length < MAX_LEN else MAX_LEN\n",
    "        \n",
    "        # Add tokens [CLS] and [SEP] at the beginning and the end\n",
    "        input_ids[k,:input_length] = np.asarray([0] + enc_text + [2], dtype='int32')\n",
    "        \n",
    "        # Set to 1s in the attention input\n",
    "        attention_mask[k,:input_length] = 1\n",
    "\n",
    "    return {\n",
    "        'input_word_ids': input_ids,\n",
    "        'input_mask': attention_mask,\n",
    "        'input_type_ids': token_type_ids\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:17:49.961889Z",
     "iopub.status.busy": "2023-05-13T12:17:49.961488Z",
     "iopub.status.idle": "2023-05-13T12:17:50.072091Z",
     "shell.execute_reply": "2023-05-13T12:17:50.071078Z",
     "shell.execute_reply.started": "2023-05-13T12:17:49.961859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform categories into numbers\n",
    "category_to_id = {}\n",
    "category_to_name = {}\n",
    "X_data = df['cleaned_review_body'].to_numpy().reshape(-1)\n",
    "y_data = df['fake_review'].to_numpy().reshape(-1)\n",
    "for index, c in enumerate(y_data):\n",
    "    if c in category_to_id:\n",
    "        category_id = category_to_id[c]\n",
    "    else:\n",
    "        category_id = len(category_to_id)\n",
    "        category_to_id[c] = category_id\n",
    "        category_to_name[category_id] = c\n",
    "    \n",
    "    y_data[index] = category_id\n",
    "\n",
    "# Display dictionary\n",
    "category_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:30:15.862147Z",
     "iopub.status.busy": "2023-05-13T12:30:15.861423Z",
     "iopub.status.idle": "2023-05-13T12:30:15.881085Z",
     "shell.execute_reply": "2023-05-13T12:30:15.880168Z",
     "shell.execute_reply.started": "2023-05-13T12:30:15.862110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split into train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=777) # random_state to reproduce results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:30:19.113067Z",
     "iopub.status.busy": "2023-05-13T12:30:19.112601Z",
     "iopub.status.idle": "2023-05-13T12:30:48.608088Z",
     "shell.execute_reply": "2023-05-13T12:30:48.606966Z",
     "shell.execute_reply.started": "2023-05-13T12:30:19.113032Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = roberta_encode(X_train, tokenizer)\n",
    "X_test = roberta_encode(X_test, tokenizer)\n",
    "\n",
    "y_train = np.asarray(y_train, dtype='int32')\n",
    "y_test = np.asarray(y_test, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:32:21.739294Z",
     "iopub.status.busy": "2023-05-13T12:32:21.738351Z",
     "iopub.status.idle": "2023-05-13T12:32:21.751933Z",
     "shell.execute_reply": "2023-05-13T12:32:21.750844Z",
     "shell.execute_reply.started": "2023-05-13T12:32:21.739253Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_categories):\n",
    "    with strategy.scope():\n",
    "        input_word_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_word_ids')\n",
    "        input_mask = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_mask')\n",
    "        input_type_ids = tf.keras.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_type_ids')\n",
    "\n",
    "        # Import RoBERTa model from HuggingFace\n",
    "        roberta_model = TFRobertaModel.from_pretrained(MODEL_NAME)\n",
    "        x = roberta_model(input_word_ids, attention_mask=input_mask, token_type_ids=input_type_ids)\n",
    "\n",
    "        # Huggingface transformers have multiple outputs, embeddings are the first one,\n",
    "        # so let's slice out the first position\n",
    "        x = x[0]\n",
    "\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dense(n_categories, activation='softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=x)\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(lr=1e-5),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:32:31.516276Z",
     "iopub.status.busy": "2023-05-13T12:32:31.514392Z",
     "iopub.status.idle": "2023-05-13T12:32:51.464271Z",
     "shell.execute_reply": "2023-05-13T12:32:51.463265Z",
     "shell.execute_reply.started": "2023-05-13T12:32:31.516233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_categories 2\n",
      "Number of replicas: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a498b5c9338b4da4989e0ae485a350b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/657M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_mask (InputLayer)        [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_type_ids (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_roberta_model (TFRobertaMod  TFBaseModelOutputWi  124645632  ['input_word_ids[0][0]',         \n",
      " el)                            thPoolingAndCrossAt               'input_mask[0][0]',             \n",
      "                                tentions(last_hidde               'input_type_ids[0][0]']         \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 128, 768)     0           ['tf_roberta_model[0][0]']       \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 98304)        0           ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          25166080    ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2)            514         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 149,812,226\n",
      "Trainable params: 149,812,226\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import RobertaTokenizer, TFRobertaModel\n",
    "categories = df['fake_review'].unique()\n",
    "n_categories = len(categories)\n",
    "print('n_categories', n_categories)\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is set (always set in Kaggle)\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "with strategy.scope():\n",
    "    model = build_model(n_categories)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T12:36:50.407681Z",
     "iopub.status.busy": "2023-05-13T12:36:50.406887Z",
     "iopub.status.idle": "2023-05-13T13:29:39.113910Z",
     "shell.execute_reply": "2023-05-13T13:29:39.112821Z",
     "shell.execute_reply.started": "2023-05-13T12:36:50.407641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/2\n",
      "2966/2966 [==============================] - 1608s 527ms/step - loss: 1.8338 - accuracy: 0.7983 - val_loss: 0.4820 - val_accuracy: 0.8133\n",
      "Epoch 2/2\n",
      "2966/2966 [==============================] - 1547s 522ms/step - loss: 0.4922 - accuracy: 0.8059 - val_loss: 0.4816 - val_accuracy: 0.8133\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n",
    "with strategy.scope():\n",
    "    print('Training...')\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        epochs=EPOCHS,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T13:30:16.861874Z",
     "iopub.status.busy": "2023-05-13T13:30:16.861354Z",
     "iopub.status.idle": "2023-05-13T13:32:38.925319Z",
     "shell.execute_reply": "2023-05-13T13:32:38.923262Z",
     "shell.execute_reply.started": "2023-05-13T13:30:16.861837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.33%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-13T13:45:21.021855Z",
     "iopub.status.busy": "2023-05-13T13:45:21.021076Z",
     "iopub.status.idle": "2023-05-13T13:47:24.572332Z",
     "shell.execute_reply": "2023-05-13T13:47:24.571107Z",
     "shell.execute_reply.started": "2023-05-13T13:45:21.021818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742/742 [==============================] - 123s 166ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90     19296\n",
      "           1       0.00      0.00      0.00      4431\n",
      "\n",
      "    accuracy                           0.81     23727\n",
      "   macro avg       0.41      0.50      0.45     23727\n",
      "weighted avg       0.66      0.81      0.73     23727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = model.predict(X_test)\n",
    "if len(preds.shape) > 1 and preds.shape[1] > 1:\n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = preds.argmax(axis=1)\n",
    "else:\n",
    "    # Convert predicted probabilities to binary labels\n",
    "    y_pred = (preds > 0.5).astype(int)\n",
    "\n",
    "# Ensure y_true and y_pred have the same shape\n",
    "y_true = y_test[:y_pred.shape[0]]  # Adjust the shape of y_true to match y_pred\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_true, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
