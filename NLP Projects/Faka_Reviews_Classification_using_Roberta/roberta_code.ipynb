{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3029982-04b2-4e52-ba71-96f9703e7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "import sklearn.metrics\n",
    "import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch import nn, tensor\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from datetime import datetime\n",
    "from os import path\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e228bf78-2138-4197-90fb-272f9e955ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train_data.csv\", encoding='cp437')\n",
    "test_data = pd.read_csv(\"test_data.csv\", encoding='cp437')\n",
    "\n",
    "\n",
    "test_data, val_data = train_test_split(test_data, test_size = 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29fc188-9bfa-4319-b46f-7b3c683a096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from datasets import Dataset, DatasetDict\n",
    "#datasets_dict = DatasetDict({\n",
    "#    \"train\": Dataset.from_pandas(train_data).remove_columns(column_names=\"__index_level_0__\"),\n",
    "#    \"test\": Dataset.from_pandas(test_data).remove_columns(column_names=\"__index_level_0__\"),\n",
    "#    \"val\": Dataset.from_pandas(val_data).remove_columns(column_names=\"__index_level_0__\")\n",
    "#})\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "datasets_dict = DatasetDict({\n",
    " \"train\": Dataset.from_pandas(train_data[['text']]),\n",
    "    \"test\": Dataset.from_pandas(test_data[['text']]),\n",
    "    \"val\": Dataset.from_pandas(val_data[['text']])\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8e57ff-1b9f-4e23-acab-4014d4365431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0220e7d5ff32410eace96aeea50ffb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f8c3678ec746c6b8c690ce6c79de8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7778d60f5aa423bb9b85992371489e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "model_type = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = datasets_dict.map(tokenize_function, batched=True)\n",
    "toke_train = tokenized_datasets['train'].shuffle()\n",
    "toke_test = tokenized_datasets['test'].shuffle()\n",
    "toke_val = tokenized_datasets['val'].shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c99ae-c9ab-4679-8850-bd7f3ae00f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80521aa86e1a46d2b2fa4f98bfe4b310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_type, num_labels=4).to(device)\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"label\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # compute custom loss (suppose one has 3 labels with different weights)\n",
    "        loss_fct = nn.CrossEntropyLoss(\n",
    "            weight=tensor([1.0, 1.0, 1.0])).to(device)\n",
    "        loss = loss_fct(\n",
    "            logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbabaf20-05a1-4a0e-b6fe-6217a49442cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Training Arguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
    "                                  logging_dir=\"test_trainer_tf\",\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  num_train_epochs=10,\n",
    "                                  warmup_ratio=0.1,\n",
    "                                  learning_rate=1.5e-6,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b84a8b-cb7f-4937-a978-4289415698a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Metrics for Training\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=toke_train,\n",
    "        eval_dataset=toke_test,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "inputs = {\"input_ids\": toke_train[\"input_ids\"], \"attention_mask\": toke_train[\"attention_mask\"], \"labels\": toke_train[\"label\"]}\n",
    "trainer.train(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa99c8e-0822-47ba-ba8f-e1a7255c2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation\n",
    "predictions = trainer.predict(toke_val)\n",
    "\n",
    "# Normalize probabilities\n",
    "probabilities = tf.nn.softmax(predictions.predictions)\n",
    "pred = np.argmax(probabilities, axis=1)\n",
    "\n",
    "# Evaluate on validation\n",
    "evaluation = trainer.evaluate(toke_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d70d91-e3a8-405c-aec9-f686a4b5f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Custom Metrics\n",
    "truth_labels = toke_val[\"label\"]\n",
    "results = pred == truth_labels\n",
    "count = np.count_nonzero(results)\n",
    "\n",
    "accuracy = count/truth_labels.__len__()\n",
    "balance_acc = sklearn.metrics.balanced_accuracy_score(truth_labels, pred)\n",
    "roc_auc = sklearn.metrics.roc_auc_score(\n",
    "    truth_labels, probabilities, multi_class='ovo', average=\"macro\")\n",
    "rho, p = spearmanr(truth_labels, pred)\n",
    "\n",
    "print(f\"Metrics:\", \"\\n\", \"Accuracy:\", round(accuracy, ndigits=2), \"\\n\",\n",
    "      \"Balanced Accuracy:\", round(balance_acc, ndigits=2), \"\\n\",\n",
    "      \"ROC_AUC:\", round(roc_auc, ndigits=2), \"\\n\",\n",
    "      \"Spearman Rank\", round(rho, ndigits=2))\n",
    "\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Metrics:\", \"\\n\", \"Accuracy:\", round(evaluation[\"accuracy\"], ndigits=2), \"\\n\",\n",
    "      \"Balanced Accuracy:\", round(evaluation[\"balanced_accuracy\"], ndigits=2), \"\\n\",\n",
    "      \"ROC_AUC:\", round(evaluation[\"roc_auc\"], ndigits=2), \"\\n\",\n",
    "      \"Spearman Rank\", round(evaluation[\"spearmanr\"], ndigits=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c611f8-c8f6-4464-85cf-c5f914a7e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Set\n",
    "\n",
    "#dev_path = pd.read_csv(\"data/test_prepros.csv\")\n",
    "\n",
    "#dev_DataSet = Dataset.from_pandas(dev_path)\n",
    "\n",
    "#dev_toke = dev_DataSet.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "#predictions = trainer().predict(dev_toke)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3a970-81ea-4457-8e3d-1e950a1185a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
