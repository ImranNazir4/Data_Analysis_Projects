{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25467f4",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9ac2e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd           #python package for data analysis\n",
    "import numpy as np            #python package for handling arrays\n",
    "import os                     #python package for dealing with system directory paths\n",
    "import docx2txt               #python package for getting data from word documents\n",
    "import neattext as nt         #python package for text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0baa046",
   "metadata": {},
   "source": [
    "# Reading the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7aa32c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir('./Anonymous_CVs/')  #give address of directory where your documents are present"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f51c507",
   "metadata": {},
   "source": [
    "# Converting the Documents into the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3e8bef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=dict()   #dictomary of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9d64a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[0:5]:\n",
    "    document= docx2txt.process('./Anonymous_CVs/'+file)   #getting text from word documents\n",
    "    documents[file]=document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "672fa80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df=pd.DataFrame(documents.items(),columns=['Document Name','Documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e781390",
   "metadata": {},
   "source": [
    "# Documents DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3ea95187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Name</th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV1.docx</td>\n",
       "      <td>Donald Petrovich\\n\\nEmail: DonaldPetrovich@gma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV2.docx</td>\n",
       "      <td>Helen Grant\\n\\n(922) 679-9797\\nHelenGrant@gmai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV3.docx</td>\n",
       "      <td>Clarence Price\\n\\n(786) 324-2395   ClarencePri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CV4.docx</td>\n",
       "      <td>Jennifer Gillman\\n\\nJenniferGillman@gmail.com\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV7.docx</td>\n",
       "      <td>Gayle Hawkins\\n\\n\\tSr. Business Systems Analys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document Name                                          Documents\n",
       "0      CV1.docx  Donald Petrovich\\n\\nEmail: DonaldPetrovich@gma...\n",
       "1      CV2.docx  Helen Grant\\n\\n(922) 679-9797\\nHelenGrant@gmai...\n",
       "2      CV3.docx  Clarence Price\\n\\n(786) 324-2395   ClarencePri...\n",
       "3      CV4.docx  Jennifer Gillman\\n\\nJenniferGillman@gmail.com\\...\n",
       "4      CV7.docx  Gayle Hawkins\\n\\n\\tSr. Business Systems Analys..."
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c7f5b",
   "metadata": {},
   "source": [
    "# Doccuments Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3badfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_cleaning(text):\n",
    "    text=nt.remove_emails(text)\n",
    "    text=nt.remove_numbers(text)\n",
    "    text=nt.remove_stopwords(text)\n",
    "    text=nt.remove_special_characters(text)\n",
    "    text=nt.remove_emojis(text)\n",
    "    text=nt.remove_phone_numbers(text)\n",
    "    text=nt.remove_multiple_spaces(text)\n",
    "    text=' '.join(text.split())\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "5a01e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Cleand_Documents']=documents_df['Documents'].apply(lambda x:docs_cleaning(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337c76ea",
   "metadata": {},
   "source": [
    "# Text Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b1498460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer   #nltk word lemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()    #creating object of word lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "a8452a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmarized_words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "52155ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#method for text lemmatization\n",
    "def lemmatization(text):\n",
    "    lemmarized_words=[]\n",
    "    tokenization = nltk.word_tokenize(text) #word tokenization using nltk word tokenizer\n",
    "    for word in tokenization:\n",
    "        word=wordnet_lemmatizer.lemmatize(word)\n",
    "        lemmarized_words.append(word)\n",
    "    return ' '.join(lemmarized_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "810273d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Lemmatized_Documents']=documents_df['Cleand_Documents'].apply(lambda x:lemmatization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdaac9",
   "metadata": {},
   "source": [
    "# Creating Word Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a47013cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "57caef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_dictionary(text):\n",
    "    word_dict=dict()\n",
    "    for word in text.split():\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word]+=1\n",
    "        else:\n",
    "            word_dict[word]=1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f2470464",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Word_Dictionary']=documents_df['Lemmatized_Documents'].apply(lambda x:word_dictionary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "286c72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing on the Document that we are going to match with our previous documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "31c89807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    text=nt.remove_emails(text)\n",
    "    text=nt.remove_numbers(text)\n",
    "    text=nt.remove_stopwords(text)\n",
    "    text=nt.remove_special_characters(text)\n",
    "    text=nt.remove_emojis(text)\n",
    "    text=nt.remove_phone_numbers(text)\n",
    "    text=nt.remove_multiple_spaces(text)\n",
    "    text=text.lower()\n",
    "    #lemmatization\n",
    "    tokenization = nltk.word_tokenize(text)\n",
    "    lemmarized_words=[]     \n",
    "    for word in tokenization:\n",
    "        word=wordnet_lemmatizer.lemmatize(word)\n",
    "        lemmarized_words.append(word)\n",
    "    return ' '.join(lemmarized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a9e89",
   "metadata": {},
   "source": [
    "# Reading our Searched Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "7e9953ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_doc= docx2txt.process('./Anonymous_CVs/CV1.docx')   #reading the document to be searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7c01498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_doc=pre_processing(searched_doc)   #applying preprocessing on the document to be searched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "9653bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating word dictionary for the document to be searched\n",
    "def searched_doc_word_dictionary(text):\n",
    "    for word in text.split():\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word]+=1\n",
    "        else:\n",
    "            word_dict[word]=1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0fdc8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_doc_dict=searched_doc_word_dictionary(searched_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca2c42",
   "metadata": {},
   "source": [
    "# Calculating the Similarity Between All the Docs with Searched Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "00ff9033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn package for text vectorization\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "cv=CountVectorizer()  #creating object of text vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "594b7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing cosine similarity for finding documents similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6fb12219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(documents,searched_document):\n",
    "    content=[str(documents.keys()),str(searched_document.keys())]\n",
    "    matrix=cv.fit_transform(content)\n",
    "    similarity_matrix=cosine_similarity(matrix)[0][1]\n",
    "    similarity=round((similarity_matrix*100),3)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "4eef871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Similarity']=documents_df['Word_Dictionary'].apply(lambda x:get_similar_docs(x,searched_doc_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc848525",
   "metadata": {},
   "source": [
    "# Similarity Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "67bffaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Document Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000</td>\n",
       "      <td>CV1.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.123</td>\n",
       "      <td>CV2.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.639</td>\n",
       "      <td>CV3.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.643</td>\n",
       "      <td>CV4.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.385</td>\n",
       "      <td>CV7.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity Document Name\n",
       "0     100.000      CV1.docx\n",
       "1      51.123      CV2.docx\n",
       "2      16.639      CV3.docx\n",
       "3      25.643      CV4.docx\n",
       "4      30.385      CV7.docx"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df[['Similarity','Document Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad76554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
