{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25467f4",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9ac2e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import docx2txt\n",
    "import neattext as nt\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.stem import PorterStemmer\n",
    "ps =PorterStemmer()\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "cv=CountVectorizer()\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7aa32c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=os.listdir('./Anonymous_CVs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3e8bef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d64a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files[0:5]:\n",
    "    document= docx2txt.process('./Anonymous_CVs/'+file)\n",
    "    documents[file]=document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "672fa80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df=pd.DataFrame(documents.items(),columns=['Document Name','Documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ea95187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Name</th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV1.docx</td>\n",
       "      <td>Donald Petrovich\\n\\nEmail: DonaldPetrovich@gma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CV2.docx</td>\n",
       "      <td>Helen Grant\\n\\n(922) 679-9797\\nHelenGrant@gmai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CV3.docx</td>\n",
       "      <td>Clarence Price\\n\\n(786) 324-2395   ClarencePri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CV4.docx</td>\n",
       "      <td>Jennifer Gillman\\n\\nJenniferGillman@gmail.com\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CV5.docx</td>\n",
       "      <td>Bonnie Pelt\\n     \\t\\t     Email/Skype: Bonnie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document Name                                          Documents\n",
       "0      CV1.docx  Donald Petrovich\\n\\nEmail: DonaldPetrovich@gma...\n",
       "1      CV2.docx  Helen Grant\\n\\n(922) 679-9797\\nHelenGrant@gmai...\n",
       "2      CV3.docx  Clarence Price\\n\\n(786) 324-2395   ClarencePri...\n",
       "3      CV4.docx  Jennifer Gillman\\n\\nJenniferGillman@gmail.com\\...\n",
       "4      CV5.docx  Bonnie Pelt\\n     \\t\\t     Email/Skype: Bonnie..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3badfdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_cleaning(text):\n",
    "    text=nt.remove_emails(text)\n",
    "    text=nt.remove_numbers(text)\n",
    "    text=nt.remove_stopwords(text)\n",
    "    text=nt.remove_special_characters(text)\n",
    "    text=nt.remove_emojis(text)\n",
    "    text=nt.remove_phone_numbers(text)\n",
    "    text=nt.remove_multiple_spaces(text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a01e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Cleand_Documents']=documents_df['Documents'].apply(lambda x:docs_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1498460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a8452a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmarized_words=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "52155ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    lemmarized_words=[]\n",
    "    tokenization = nltk.word_tokenize(text)\n",
    "    for word in tokenization:\n",
    "        word=wordnet_lemmatizer.lemmatize(word)\n",
    "        lemmarized_words.append(word)\n",
    "    return ' '.join(lemmarized_words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "810273d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Lemmatized_Documents']=documents_df['Cleand_Documents'].apply(lambda x:lemmatization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "51b7daaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    donald petrovich email phone current location ...\n",
       "1    helen grant objective year strong software exp...\n",
       "2    clarence price project manager experienced pro...\n",
       "3    jennifer gillman certified scrum master busine...\n",
       "4    bonnie pelt emailskype mob professional summar...\n",
       "Name: Lemmatized_Documents, dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df['Lemmatized_Documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a47013cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "57caef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_dictionary(text):\n",
    "    for word in text.split():\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word]+=1\n",
    "        else:\n",
    "            word_dict[word]=1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f2470464",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Word_Frequencies']=documents_df['Lemmatized_Documents'].apply(lambda x:word_dictionary(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "31c89807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(text):\n",
    "    text=nt.remove_emails(text)\n",
    "    text=nt.remove_numbers(text)\n",
    "    text=nt.remove_stopwords(text)\n",
    "    text=nt.remove_special_characters(text)\n",
    "    text=nt.remove_emojis(text)\n",
    "    text=nt.remove_phone_numbers(text)\n",
    "    text=nt.remove_multiple_spaces(text)\n",
    "    text=text.lower()\n",
    "    tokenization = nltk.word_tokenize(text)\n",
    "    lemmarized_words=[]\n",
    "    for word in tokenization:\n",
    "        word=wordnet_lemmatizer.lemmatize(word)\n",
    "        lemmarized_words.append(word)\n",
    "    return ' '.join(lemmarized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7e9953ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "document= docx2txt.process('./Anonymous_CVs/CV1.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7c01498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=pre_processing(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9653bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_dictionary(text):\n",
    "    for word in text.split():\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word]+=1\n",
    "        else:\n",
    "            word_dict[word]=1\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0fdc8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_dict=word_dictionary(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6fb12219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(documents,searched_document):\n",
    "    content=[list(documents.values()),list(searched_document.values())]\n",
    "    #matrix=cv.fit_transform(content)\n",
    "    similarity_matrix=cosine_similarity(content)[0][1]\n",
    "    similarity=round((similarity_matrix*100),3)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4eef871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df['Sim']=documents_df['Word_Frequencies'].apply(lambda x:get_similar_docs(x,document_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "67bffaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100.000\n",
       "1     82.774\n",
       "2     10.857\n",
       "3     21.013\n",
       "4     31.377\n",
       "Name: Sim, dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df['Sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074818ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
