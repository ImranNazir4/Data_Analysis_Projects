{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45668655",
   "metadata": {},
   "source": [
    "# NLE / ANLP \n",
    "\n",
    "## Practice Computer-based Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29887aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###update your candidate number here\n",
    "candidate_number=11111111\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1178c6",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "This question is about part-of-speech tagging, named entity recognition and sentiment classification.\n",
    "\n",
    "You will be using a corpus of movie reviews which is loaded and split into a training and a testing set in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358efe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "#preliminary imports\n",
    "\n",
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n",
    "\n",
    "#functions to load and split the movie review data\n",
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the \n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = list(data)  \n",
    "    n = len(data)  \n",
    "    train_indices = random.sample(range(n), int(n * ratio))          \n",
    "    test_indices = list(set(range(n)) - set(train_indices))    \n",
    "    train = [data[i] for i in train_indices]           \n",
    "    test = [data[i] for i in test_indices]             \n",
    "    return (train, test)                       \n",
    " \n",
    "\n",
    "def get_train_test_data():\n",
    "    \n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "   \n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.raw(f),'pos') for f in pos_train_ids]+[(movie_reviews.raw(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.raw(f),'pos') for f in pos_test_ids]+[(movie_reviews.raw(f),'neg') for f in neg_test_ids]\n",
    "   \n",
    "    return training, testing\n",
    "\n",
    "random.seed(42)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2e48fe",
   "metadata": {},
   "source": [
    "a) Run the SpaCy part-of-speech tagger and named entity recogniser on the first review in the training data.  Use code to establish:\n",
    "\n",
    "i) the number of distinct part-of-speech tags used and the frequency of each part of speech tag (in the first review).\n",
    "\n",
    "ii) the number of distinct named entity labels used and the frequency of each named entity labels (in the first review).\n",
    "\n",
    "iii) considering only those tokens labelled as named entity tags, the number of distinct part-of-speech tags and the frequency of each part of speech tag (in the first review).\n",
    "\n",
    "[15 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8c391",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc9b72eb",
   "metadata": {},
   "source": [
    "b) Comment on the results.  How might your observations be useful when building a named entity recognition system.\n",
    "[5 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3c1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92fc43f6",
   "metadata": {},
   "source": [
    "c) Write a function which extracts all of the occurrences of adjectives from a text.  Display the adjectives in the first review. [10 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a37c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "330a743f",
   "metadata": {},
   "source": [
    "d) Imagine you are building a Naive Bayes classifier to predict whether a review is positive or negative based on the words it contains.\n",
    "\n",
    "i) What probabilities are needed to formulate the Naive Bayes model?\n",
    "\n",
    "ii) How are these probabililites estimated?\n",
    "\n",
    "iii) How are these probabilities used to determine the most likely class given the observed words in the target review?\n",
    "\n",
    "iv) What is add-one smoothing and why is it used in NB classification?\n",
    "[10 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243758a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9029f1c7",
   "metadata": {},
   "source": [
    "d) Describe an experiment you could carry out to test whether adjectives or more useful than other parts-of-speech when using a Naive Bayes classifier to classify reviews as being positive or negative in sentiment.\n",
    "[10 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e467df15",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
