{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12541c12",
   "metadata": {},
   "source": [
    "# 1 - Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd              #python package for data analysis\n",
    "import numpy as np               #python package for arrays handling\n",
    "import seaborn as sns            #python package for data visualization\n",
    "import matplotlib.pyplot as plt  #python package for data visualization\n",
    "import neattext as nt            #python package for text data cleaning\n",
    "import nltk                       #python package for text data analysis\n",
    "from nltk.stem import WordNetLemmatizer   #python package for text lemmatization\n",
    "from wordcloud import WordCloud           #python package for word clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a458697e",
   "metadata": {},
   "source": [
    "# 2 - Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663c9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df=pd.read_csv('Huff_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8d283",
   "metadata": {},
   "source": [
    "### 3 - Joining the 'headline' and 'short_descriptions' data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3592c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['news_text']=news_df.apply(lambda x:str(x['headline'])+str(' ')+str(x['short_description']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1058a1ea",
   "metadata": {},
   "source": [
    "### Dropping Un-necessary Data Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2145ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.drop(['Unnamed: 0', 'authors', 'link','short_description'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7a127",
   "metadata": {},
   "source": [
    "### Checking Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6f9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bcabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.dropna(axis=1,inplace=True)  #dropping null values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886cd0c5",
   "metadata": {},
   "source": [
    "### Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=''.join(news_df['news_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba8cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=nt.remove_stopwords(text)\n",
    "text=nt.remove_special_characters(text)\n",
    "text=nt.remove_shortwords(text,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14dca7c",
   "metadata": {},
   "source": [
    "### Most Used Word in News Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d3dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(text)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa374f1",
   "metadata": {},
   "source": [
    "### New Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b336063",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "news_df.category.value_counts().plot(kind=\"bar\")\n",
    "plt.annotate(\"Most Repeated News Category\",xy=(0,3550))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Distribution of New Categories\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f66ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text=nt.fix_contractions(text)               #I'm -->I am\n",
    "    text=nt.remove_special_characters(text)      #(),&,<,^...\n",
    "    text=nt.remove_stopwords(text)               #is,are,the,..\n",
    "    text=nt.remove_puncts(text)                  #,.:;\n",
    "    text=nt.remove_bad_quotes(text)              #'b''\n",
    "    text=nt.remove_emojis(text)                  #emojis\n",
    "    text=nt.remove_numbers(text)                 #1,2,3,...\n",
    "    text=nt.remove_shortwords(text,3)            #removing short words of length 3 \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14dd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['news_text']=news_df['news_text'].apply(lambda x:text_cleaning(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9735ef",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WordNet lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()    #convert words to their base words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d65d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_lemmatization(text):\n",
    "    # Tokenize the sentence into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Lemmatize each word in the sentence\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcc853",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df['news_text']=news_df['news_text'].apply(lambda x:text_lemmatization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09d60df",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de575a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  #text vectorizing using Tfidf vectorizer\n",
    "vect=TfidfVectorizer(max_features=4000)  #creating object of tfidf vectorizer\n",
    "X=vect.fit_transform(news_df.news_text)  #vectorizing news_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=news_df['category']   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba886d",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecabea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #importing train test split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedf3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,stratify=y,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "# Importing Evaluation matrces\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report, plot_confusion_matrix\n",
    "\n",
    "# check the performance on diffrent regressor\n",
    "models = []\n",
    "models.append(('Support Vector Classifier', svm.SVC()))\n",
    "models.append(('LogisitcRegression', LogisticRegression()))\n",
    "models.append(('NaiveBayesClassifier', MultinomialNB()))\n",
    "\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "# metrices to store performance\n",
    "acc = []\n",
    "pre = []\n",
    "f1 = []\n",
    "con = []\n",
    "rec = []\n",
    "\n",
    "\n",
    "import time\n",
    "i = 0\n",
    "for name,model in models:\n",
    "    i = i+1\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fitting model to the Training set\n",
    "    clf = model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # predict values\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc.append(accuracy)\n",
    "    # Precision\n",
    "    precision = precision_score(y_test, y_pred, average=None)\n",
    "    pre.append(precision)\n",
    "    # Recall\n",
    "    recall = recall_score(y_test, y_pred, average=None)\n",
    "    rec.append(recall)\n",
    "    # F1 Score\n",
    "    f1_sco = f1_score(y_test, y_pred, average=None)\n",
    "    f1.append(f1_sco)\n",
    "    # Confusion Matrix\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    con.append(confusion_mat)\n",
    "    # Report\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # evaluate model\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"+\",\"=\"*100,\"+\")\n",
    "    print('\\033[1m' + f\"\\t\\t\\t{i}-For {name} The Performance result is: \" + '\\033[0m')\n",
    "    print(\"+\",\"=\"*100,\"+\")\n",
    "    print('Accuracy : ', accuracy)   \n",
    "    print(\"-\"*50)\n",
    "    print('F1 : ', f1_sco)\n",
    "    print(\"-\"*50)\n",
    "    print('Reacll : ', recall)\n",
    "    print(\"-\"*50)\n",
    "    print('Precision : ', precision)\n",
    "    print(\"-\"*50)\n",
    "    print('cross validation accuracy : ', np.mean(scores))\n",
    "    print(\"-\"*50)\n",
    "    print('Confusion Matrix....\\n', confusion_mat)\n",
    "    print(\"-\"*50)\n",
    "    print('Classification Report....\\n', report)\n",
    "    print(\"-\"*50)\n",
    "    print('Plotting Confusion Matrix...\\n')\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    plot_confusion_matrix(clf, X_test, y_test,ax=ax)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"\\t\\t\\t\\t\\t\\t\\t-----------------------------------------------------------\")\n",
    "    print(f\"\\t\\t\\t\\t\\t\\t\\t Time for detection ({name}) : {round((time.time() - start_time), 3)} seconds...\")\n",
    "    print(\"\\t\\t\\t\\t\\t\\t\\t-----------------------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "pd.DataFrame({\"Model\": dict(models).keys(), \"Accuracy\": acc, \"Precision\": pre, \"Recall\": rec, \"F1_Score\": f1, \"Confusion Matrix\": con})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6544ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
