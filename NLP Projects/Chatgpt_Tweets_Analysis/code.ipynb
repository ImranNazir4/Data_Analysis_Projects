{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxyARJY46vKO"
   },
   "source": [
    "### snscrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkPEhJn_Kga0"
   },
   "source": [
    "- Twitter is also known for being an abundant source of publc text data (perhaps even more so than Reddit).\n",
    "- For this tutorial, we'll look at using the [snscrape scraper](https://github.com/JustAnotherArchivist/snscrape), which allows us to retreive tweets that contain specific words, phrases, and hashtags.\n",
    "- In the slides, we talked about how to setup a Twitter App and get a API keys.\n",
    "    - You should add your own keys below and then run the code block to set your keys:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65zz7hg4mS_Y"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yv5g0fzugV-F"
   },
   "source": [
    "# **Installing snscrape:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_F6zB9qxgV-F"
   },
   "outputs": [],
   "source": [
    "!pip3 install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0qZXyXLchnwZ"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ozTZ-ahgV-F"
   },
   "source": [
    "# **Running snscrape from command line:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ps-ss8W2gV-G"
   },
   "outputs": [],
   "source": [
    "#snscrape --jsonl --progress --max-results 100 --since 2022-01-01 twitter-search \"chatgpt filter:verified lang:en until:2023-01-02\" > tweets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGsxzZ6NgV-G",
    "tags": []
   },
   "source": [
    "# A simple python code to scrape Twitter using snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p64CR2m2gV-H"
   },
   "outputs": [],
   "source": [
    "os.system('snscrape --jsonl --progress --max-results 100000 --since 2022-01-01 twitter-search \"chatgpt filter:verified lang:en until:2023-01-02\" > tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GOBBPNWxAYG"
   },
   "source": [
    "# **Installing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "noiKLYcomoaG"
   },
   "outputs": [],
   "source": [
    "!pip install -q neattext\n",
    "!pip install -q textblob==0.17.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EBBu7ShxQOs"
   },
   "source": [
    "# **Importing Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tyDiDMUmbim"
   },
   "outputs": [],
   "source": [
    "import pandas as pd                           #package for data analysis\n",
    "import numpy as np                            #package for handling arrays \n",
    "import matplotlib.pyplot as plt               #package for data visualizations\n",
    "import neattext as nt                         #package for text cleaning\n",
    "import seaborn as sns                         #package for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnAP5u2HxVlu"
   },
   "source": [
    "# **Reading the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9clPU9t4mbfu"
   },
   "outputs": [],
   "source": [
    "df=pd.read_json(\"tweets.json\",lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bc20a4ziZD7"
   },
   "source": [
    "# **Feature of the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKe9jUetmbck"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSaIPeIambYO"
   },
   "outputs": [],
   "source": [
    "df.rename({'renderedContent':'tweet_text'},axis=1,inplace=True)   #renaming feature name renderedContent to tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B04aXdrQxakC"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "euguyGcspIoi"
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "  text=nt.fix_contractions(text)     #I'm -> I am\n",
    "  text=nt.remove_urls(text)          #removing urls\n",
    "  text=nt.remove_non_ascii(text)     #removing non-ascii characters\n",
    "  text=nt.remove_userhandles(text)   #removing urserhandles\n",
    "  text=nt.remove_hashtags(text)      #removing hashtags\n",
    "  text=nt.remove_multiple_spaces(text)  #removing multiple spaces\n",
    "  return text\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wx4IF2zJqBKA"
   },
   "outputs": [],
   "source": [
    "df.tweet_text=df.tweet_text.apply(lambda x:text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7JdJ0ymxj2r"
   },
   "source": [
    "# **Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gib8fXFwmbGj"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob   #special package for short sentence sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yt0duqVOmbDT"
   },
   "outputs": [],
   "source": [
    "def sentiment_polarity(text):\n",
    "  '''\n",
    "  this fucntion calculates polarity of each tweet\n",
    "  '''\n",
    "  text=TextBlob(text)\n",
    "  return text.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvpnBT2ombAK"
   },
   "outputs": [],
   "source": [
    "df['sentiment_polarity']=df.tweet_text.apply(lambda x:sentiment_polarity(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8jLannnJma8a"
   },
   "outputs": [],
   "source": [
    "def sentiment_tag(polarity):\n",
    "  '''\n",
    "  this function assigns sentiment tag according to its polarity\n",
    "  '''\n",
    "  if polarity>0:\n",
    "        return 'positive'\n",
    "  elif polarity<0:\n",
    "        return 'negative'\n",
    "  else:\n",
    "    return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrQ3KiLuma4j"
   },
   "outputs": [],
   "source": [
    "df['sentiment_tag']=df['sentiment_polarity'].apply(lambda x:sentiment_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSs9DR0ljy-A"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=df['sentiment_tag'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pq-M2qFXjiWo"
   },
   "source": [
    "# **Word Cloud Visualizaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4pHxh19mayS"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYL9TctlmavJ"
   },
   "outputs": [],
   "source": [
    "all_words = ' '.join(df['sentiment_tag'])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjLR62c-kEpU"
   },
   "source": [
    "# **Emotion Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ah4eCyc_S-D"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers \n",
    "from transformers import pipeline\n",
    "emotion = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qODeili_S6j"
   },
   "outputs": [],
   "source": [
    "df['Emotions']=df['tweet_text'].apply(emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_uffdzt_S2n"
   },
   "outputs": [],
   "source": [
    "def extract_em(em_dict):\n",
    "  return em_dict[0]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inWq0pgo_SzO"
   },
   "outputs": [],
   "source": [
    "df['Emotions_Label']=df['Emotions'].apply(lambda x:extract_em(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04slEmA2_Su8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.countplot(x=df['Emotions_Label'])\n",
    "plt.title('Emotions Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws4enW8bkQET"
   },
   "source": [
    "# **Postprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fTQxqovrvquc"
   },
   "outputs": [],
   "source": [
    "df['tweet_text']=df['tweet_text'].apply(lambda x:nt.remove_special_characters(x))\n",
    "df['tweet_text']=df['tweet_text'].apply(lambda x:nt.remove_numbers(x))\n",
    "df['tweet_text']=df['tweet_text'].apply(lambda x:nt.remove_stopwords(x))\n",
    "df['tweet_text']=df['tweet_text'].apply(lambda x:nt.remove_shortwords(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lgs4yNwcmaq0"
   },
   "outputs": [],
   "source": [
    "all_words = ' '.join(df['tweet_text'])\n",
    "wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnqidSUuman9"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlTSmv7q12X2"
   },
   "source": [
    "# **Tweets by Month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JD9A6jow0YH6"
   },
   "outputs": [],
   "source": [
    "df.index=df.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CgCMF6dE0rZ8"
   },
   "outputs": [],
   "source": [
    "tweets_by_month=df.loc[:,'tweet_text'].resample('m').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_Ut0fp401Gc"
   },
   "outputs": [],
   "source": [
    "tweets_by_month.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ef68-kdtmak1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(x=df['sourceLabel'].value_counts()[0:10].index,y=df['sourceLabel'].value_counts()[0:10].values)\n",
    "plt.title('Tweet Sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PL4By2V0maQY"
   },
   "outputs": [],
   "source": [
    "corpus=''.join(df['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NS8r04S6f16"
   },
   "outputs": [],
   "source": [
    "#corpus=[word for word in corpus.split()]\n",
    "corpus=list(corpus.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sD90vFLTmaM1"
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary([corpus])\n",
    "# Create Corpus\n",
    "texts = [corpus]\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJtbGUClkclc"
   },
   "source": [
    "# **Topic Modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RGFYa5Xp81Jk"
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BACiO0VmaIm"
   },
   "outputs": [],
   "source": [
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                      num_topics=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDyLsTCMmaDE"
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUNqzeyM-AYZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93pfIVzr-AUk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQ0zaHiL-AQx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kR200z-k7lf"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
