{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "weighted-turner",
   "metadata": {
    "id": "mufXIP9MxhHp"
   },
   "source": [
    "# NLP First Assignment - Spam Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-forge",
   "metadata": {
    "id": "7hlrpStixpuX"
   },
   "source": [
    "Import necessary modules. \n",
    "\n",
    "**If these cells fail, you won't be able to run the whole notebook. Make sure that you are able to import all the needed packages!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43455642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551f257",
   "metadata": {},
   "source": [
    "Make sure to match the cuda version of spacy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39981ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in i:\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 125.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in i:\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages (65.5.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-67.6.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 129.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in i:\\wpsystem\\s-1-5-21-2818287816-1769971900-1840473298-1002\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.38.4)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "     -------------------------------------- 64.5/64.5 kB 119.9 kB/s eta 0:00:00\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.38.4\n",
      "    Uninstalling wheel-0.38.4:\n",
      "      Successfully uninstalled wheel-0.38.4\n",
      "Successfully installed pip-23.0.1 setuptools-67.6.1 wheel-0.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'C:\\Users\\Zee Tech\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pip.exe, pip3.10.exe and pip3.exe are installed in 'C:\\Users\\Zee Tech\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\Zee Tech\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: \"'spacy[cuda112]'\"\n"
     ]
    }
   ],
   "source": [
    "#Update Spacy for 3.0 functionality (new features), install GPU support for better performance\n",
    "!pip install -U pip setuptools wheel\n",
    "!pip install --upgrade 'spacy[cuda112]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stunning-motorcycle",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "stretch-occasions",
    "outputId": "0d812f55-ba5d-4f48-9d0c-9385711d5da4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-setup",
   "metadata": {
    "id": "banner-flexibility"
   },
   "source": [
    "## 1. Task - Corpus visualization (2 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "heated-silly",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUHcBVTo4N-D",
    "outputId": "1fbe80db-b828-40e3-ef03-963af8443e5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download corpus\n",
    "!wget http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/smsspamcollection.zip\n",
    "!unzip smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-mobility",
   "metadata": {},
   "source": [
    "- Read in the data into the `df` variable. \n",
    "- Display the first 5 rows of the DataFrame. \n",
    "- Check if there are missing values in the database.\n",
    "\n",
    "*Hint: use pandas's `read_csv` method, the dataset does not have headers, and each column is separated by a tab.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "metropolitan-escape",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "exact-mailing",
    "outputId": "84ff021d-65c1-4e82-a3d3-f3178f930fed",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "df=pd.read_csv(\"SMSSpamCollection.txt\",sep=\"\\t\",names=[\"label\",\"sms\"])\n",
    "df.head()\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-temple",
   "metadata": {},
   "source": [
    "- Discribe the database below in one or two sentences.\n",
    "- The given database is of messages that are labeled either spam or ham. There are 5573 records and 2 columns. The 482 records are ham  and 747 are spam. The given data is severely imbalanced.\n",
    "\n",
    "    **YOUR SOLUTION COMES HERE...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b952ad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "sms      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baf69cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df9a2a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-dating",
   "metadata": {
    "id": "alternative-rogers"
   },
   "source": [
    "## 2. Task - Spacy POS-tagging and tokenization (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-registrar",
   "metadata": {
    "id": "FjbMTTqXyELu"
   },
   "source": [
    "- Download the `en_core_web_sm` spacy English model.\n",
    "- Load the model into the nlp variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prerequisite-sierra",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alert-project",
    "outputId": "0e5d6bbd-2754-4964-c391-7113bfffd49f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zee tech\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\spacy\\util.py:877: UserWarning: [W095] Model 'en_core_web_sm' (3.2.0) was trained with spaCy v3.2 and may not be 100% compatible with the current version (3.4.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "########################## Implement your solution ABOVE ##########################\n",
    "print(\"Pipeline:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-estimate",
   "metadata": {
    "id": "q6ItemUQyRyx"
   },
   "source": [
    "### Define a function for tokenization which,\n",
    "  - Takes two arguments: a list of strings - SMSs - to be tokenized and an nlp model\n",
    "  - Returns the tokenized version of each email in a `Doc` object in a list\n",
    "\n",
    "  **Be smart with how you achieve the tokenization. We only accept an optimal (fast) solution!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbfe4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "def tokenize(sms, spacy_nlp):\n",
    "    tokens=[]\n",
    "    doc = spacy_nlp(sms)\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-supplier",
   "metadata": {
    "id": "7_PJzS4SyX0V"
   },
   "source": [
    "- Construct a \"tokenized\" column to our original database, with your `tokenize` function applied to the data from the appropriate column of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627c8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized\"]=df[\"sms\"].apply(lambda x:tokenize(x,nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60908916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...  \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]  \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...  \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...  \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-creator",
   "metadata": {
    "id": "N7310SBGybBJ"
   },
   "source": [
    "### Define a function for POS tagging, which\n",
    "  - Takes the tokenized document (string) - a Doc object - as the only parameter\n",
    "  - Returns a list with the POS tags (string) of each token in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "center-terry",
   "metadata": {
    "id": "compact-skating"
   },
   "outputs": [],
   "source": [
    "def pos_tag(tokens):\n",
    "    pos_list= []\n",
    "    ######################## Implement your solution BELOW ########################\n",
    "    doc=nlp(\" \".join(tokens))\n",
    "    for token in doc:\n",
    "        pos_list.append(token.pos_)\n",
    "    ######################## Implement your solution ABOVE ########################\n",
    "    return pos_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-census",
   "metadata": {
    "id": "_J9C6uYiyv8Z"
   },
   "source": [
    "- Construct a `pos_tagged` column to our original database, with your `pos_tag` function applied to the data from the appropriate column of our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "479cdfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos_tagged\"]=df[\"tokenized\"].apply(lambda x:pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19c60b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[VERB, ADP, PROPN, NOUN, PUNCT, ADJ, PUNCT, AD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[INTJ, ADJ, PUNCT, VERB, NOUN, PROPN, NOUN, PU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[ADJ, NOUN, ADP, NUM, DET, ADJ, NOUN, PART, VE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                          pos_tagged  \n",
       "0  [VERB, ADP, PROPN, NOUN, PUNCT, ADJ, PUNCT, AD...  \n",
       "1  [INTJ, ADJ, PUNCT, VERB, NOUN, PROPN, NOUN, PU...  \n",
       "2  [ADJ, NOUN, ADP, NUM, DET, ADJ, NOUN, PART, VE...  \n",
       "3  [PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, NO...  \n",
       "4  [INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-appearance",
   "metadata": {
    "id": "african-sydney"
   },
   "source": [
    "## 3. Task - Spacy stopword filtering (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-labor",
   "metadata": {
    "id": "xcs-es7Ry2IA"
   },
   "source": [
    "Use Spacy to apply stopword filtering to the corpus. Remove words like \"is\", \"a\", etc. \n",
    "\n",
    "Run the following cell, to import `STOP_WORDS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satellite-assumption",
   "metadata": {
    "id": "acute-atlantic"
   },
   "outputs": [],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-staff",
   "metadata": {
    "id": "QvMn1PI4zL6B"
   },
   "source": [
    "Define the stopword filtering function which also lemmatizes the tokens and,\n",
    "  - Takes the tokenized document (string) - a Doc object - as the only parameter\n",
    "  - And returns a list of strings with the stop words filtered and the tokens reduced to their lemmas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "necessary-destiny",
   "metadata": {
    "id": "proved-cannon"
   },
   "outputs": [],
   "source": [
    "def stopword_filter_and_lematize(tokens):\n",
    "    filtered_lemmas= []\n",
    "    ######################## Implement your solution BELOW ########################\n",
    "    doc=nlp(\" \".join(tokens))\n",
    "    filtered_tokens = [token.text for token in doc if not token.is_stop]   #stopwords filtering\n",
    "    filtered_tokens= \" \".join(filtered_tokens)\n",
    "    doc=nlp(filtered_tokens)\n",
    "    filtered_lemmas = [token.lemma_ for token in doc]           #lemmatization\n",
    "    ######################## Implement your solution ABOVE ########################\n",
    "    return filtered_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-beach",
   "metadata": {
    "id": "u7u4qAVzzbki"
   },
   "source": [
    "- Construct a `stopword_filtered_lemmas` column to our original database, with your `stopword_filter_and_lematize` function applied to the data from the appropriate column of the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac98c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stopword_filtered_lemmas\"]=df[\"tokenized\"].apply(lambda x:stopword_filter_and_lematize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abandoned-saturn",
   "metadata": {
    "id": "focused-shipping"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>pos_tagged</th>\n",
       "      <th>stopword_filtered_lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>[Go, until, jurong, point, ,, crazy, .., Avail...</td>\n",
       "      <td>[VERB, ADP, PROPN, NOUN, PUNCT, ADJ, PUNCT, AD...</td>\n",
       "      <td>[jurong, point, ,, crazy, .., available, bugis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[Ok, lar, ..., Joking, wif, u, oni, ...]</td>\n",
       "      <td>[INTJ, ADJ, PUNCT, VERB, NOUN, PROPN, NOUN, PU...</td>\n",
       "      <td>[ok, lar, ..., joke, wif, u, oni, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[Free, entry, in, 2, a, wkly, comp, to, win, F...</td>\n",
       "      <td>[ADJ, NOUN, ADP, NUM, DET, ADJ, NOUN, PART, VE...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, FA, Cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[U, dun, say, so, early, hor, ..., U, c, alrea...</td>\n",
       "      <td>[PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, NO...</td>\n",
       "      <td>[U, dun, early, hor, ..., u, c, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>[Nah, I, do, n't, think, he, goes, to, usf, ,,...</td>\n",
       "      <td>[INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...</td>\n",
       "      <td>[Nah, think, go, usf, ,, live]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [Go, until, jurong, point, ,, crazy, .., Avail...   \n",
       "1           [Ok, lar, ..., Joking, wif, u, oni, ...]   \n",
       "2  [Free, entry, in, 2, a, wkly, comp, to, win, F...   \n",
       "3  [U, dun, say, so, early, hor, ..., U, c, alrea...   \n",
       "4  [Nah, I, do, n't, think, he, goes, to, usf, ,,...   \n",
       "\n",
       "                                          pos_tagged  \\\n",
       "0  [VERB, ADP, PROPN, NOUN, PUNCT, ADJ, PUNCT, AD...   \n",
       "1  [INTJ, ADJ, PUNCT, VERB, NOUN, PROPN, NOUN, PU...   \n",
       "2  [ADJ, NOUN, ADP, NUM, DET, ADJ, NOUN, PART, VE...   \n",
       "3  [PROPN, PROPN, VERB, ADV, ADJ, NOUN, PUNCT, NO...   \n",
       "4  [INTJ, PRON, AUX, PART, VERB, PRON, VERB, ADP,...   \n",
       "\n",
       "                            stopword_filtered_lemmas  \n",
       "0  [jurong, point, ,, crazy, .., available, bugis...  \n",
       "1             [ok, lar, ..., joke, wif, u, oni, ...]  \n",
       "2  [free, entry, 2, wkly, comp, win, FA, Cup, fin...  \n",
       "3               [U, dun, early, hor, ..., u, c, ...]  \n",
       "4                     [Nah, think, go, usf, ,, live]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-attitude",
   "metadata": {
    "id": "apart-integration"
   },
   "source": [
    "## 4. Task - Prepare the data for classification (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-animation",
   "metadata": {
    "id": "hrbrCDZe0Ets"
   },
   "source": [
    "We would like to do binary classification into two categories: spam and not spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-extra",
   "metadata": {},
   "source": [
    "- Construct a new column named `label` to our database by transforming the string labels \"ham\" and \"spam\" of the appropriate column into machine understandable binary values.\n",
    "\n",
    "  - *Hint: Use the `apply` method!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impaired-college",
   "metadata": {
    "id": "southeast-panic"
   },
   "outputs": [],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "df[\"label\"]=df[\"label\"].apply(lambda x:1 if x==\"spam\" else 0)   #replacing ham with 0 spam with 1\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-complement",
   "metadata": {},
   "source": [
    "- Split the database into train and test sets, save both into `df_train` and `df_test` respectively.\n",
    "\n",
    "*Hint: Don't forget to shuffle the database before the split!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0187440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "transsexual-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df,test_size=0.20,random_state=23)\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-toyota",
   "metadata": {},
   "source": [
    "- Construct a `TfidfVectoreizer` model, which\n",
    "  - uses the `\"word\"` analyzer\n",
    "  - its token pattern is `None`\n",
    "  - **and make sure to specify the `tokenizer` and the `preprocessor` as the identity function.**\n",
    "    - *Note: The reason behind this is that we already did these steps with `spacy`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "relevant-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea267619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_tokenizer(stopword_filtered_leamms):\n",
    "    return \" \".join(stopword_filtered_leamms)\n",
    "\n",
    "def identity_preprocessor(stopword_filtered_leamms):\n",
    "    return \" \".join(stopword_filtered_leamms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worst-bhutan",
   "metadata": {
    "id": "improved-plenty"
   },
   "outputs": [],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "vectorizer = TfidfVectorizer(analyzer='word', token_pattern=None,\n",
    "                        tokenizer=identity_tokenizer, preprocessor=identity_preprocessor)\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-senator",
   "metadata": {},
   "source": [
    "- Use the `df_train` set's `stopword_filtered_leamms` column to fit the vectorizer and transform the data to the `x_train` variable.\n",
    "  - *Hint: There is a method for exactly this.*\n",
    "- Use the trained vectorizer to transform the `df_test` set's `stopword_filtered_leamms` column and save the result into the `x_test` variable.\n",
    "- Create the `y_train` and `y_test` variables by copying the data from the appropriate set's `label` column to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "deluxe-season",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 112) (4457,)\n",
      "(1115, 112) (1115,)\n"
     ]
    }
   ],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "x_train=vectorizer.fit_transform(df_train[\"stopword_filtered_lemmas\"])\n",
    "x_test=vectorizer.transform(df_test[\"stopword_filtered_lemmas\"])\n",
    "y_train=df_train.label\n",
    "y_test=df_test.label\n",
    "########################## Implement your solution ABOVE ##########################\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-crack",
   "metadata": {},
   "source": [
    "## 5. Task - ML-based Classification (5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-conducting",
   "metadata": {
    "id": "ZFaZWApLz4nS"
   },
   "source": [
    "You should compare 3 machine learning based classifications models by evaluating their performance on the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-encoding",
   "metadata": {},
   "source": [
    "Use the `metrics` module to evaluate the performance of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "horizontal-facility",
   "metadata": {
    "id": "proprietary-question"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-neighbor",
   "metadata": {
    "id": "fuzzy-beach"
   },
   "source": [
    "### 5/a. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "institutional-growth",
   "metadata": {
    "id": "hollywood-packaging"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-capital",
   "metadata": {
    "id": "UPixC_Y02p0X"
   },
   "source": [
    "- Train multiple `RandomForestClassifier`s. It has a hyperparameter, namely the depth of the tree. Explore how different values effect the performance by testing with 4 different depths.\n",
    "  - *Hint: Make sure to initalize each RandomForest with the same random state to achieve a fair comparison.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aboriginal-samba",
   "metadata": {
    "id": "dated-michigan"
   },
   "outputs": [],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "rnd_forest_clf_list=RandomForestClassifier()\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-voice",
   "metadata": {
    "id": "VJbTt6lD3RwR"
   },
   "source": [
    "- Predict with each `RandomForestClassifier` into the `rnd_test_perds` list.\n",
    "- Evaluate the results of each classifier with the results of the following functions from the `metrics` module:\n",
    "  - The `accuracy_score` (save the results into the `rnd_acc_list` variable).\n",
    "  - The `balanced_accuracy_score` (save the results into the `rnd_bal_acc_list` varaible).\n",
    "  - The `confusion_matrix` (save the results into the `rnd_conf_mtx_list` variable).\n",
    "- Print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a485788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for max_depth=5:\n",
      "Accuracy score: 0.9829596412556054\n",
      "Balanced accuracy score: 0.9379084967320261\n",
      "Confusion matrix:\n",
      "[[962   0]\n",
      " [ 19 134]]\n",
      "\n",
      "Results for max_depth=10:\n",
      "Accuracy score: 0.9874439461883409\n",
      "Balanced accuracy score: 0.9542483660130718\n",
      "Confusion matrix:\n",
      "[[962   0]\n",
      " [ 14 139]]\n",
      "\n",
      "Results for max_depth=15:\n",
      "Accuracy score: 0.989237668161435\n",
      "Balanced accuracy score: 0.9635325370619489\n",
      "Confusion matrix:\n",
      "[[961   1]\n",
      " [ 11 142]]\n",
      "\n",
      "Results for max_depth=20:\n",
      "Accuracy score: 0.9874439461883409\n",
      "Balanced accuracy score: 0.9569965893495305\n",
      "Confusion matrix:\n",
      "[[961   1]\n",
      " [ 13 140]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the values of max_depth to try\n",
    "max_depths = [5, 10, 15, 20]\n",
    "\n",
    "# Create a list to store the classifiers, accuracy scores, balanced accuracy scores, and confusion matrices\n",
    "rnd_forest_clf_list = []\n",
    "rnd_acc_list = []\n",
    "rnd_bal_acc_list = []\n",
    "rnd_conf_mtx_list = []\n",
    "\n",
    "# Loop over the values of max_depth and fit a classifier for each value\n",
    "for max_depth in max_depths:\n",
    "    clf = RandomForestClassifier(max_depth=max_depth)\n",
    "    clf.fit(x_train, y_train)\n",
    "    rnd_forest_clf_list.append(clf)\n",
    "    \n",
    "    # Make predictions on the test data and evaluate the performance\n",
    "    rnd_test_perds = clf.predict(x_test)\n",
    "    rnd_acc_list.append(accuracy_score(y_test, rnd_test_perds))\n",
    "    rnd_bal_acc_list.append(balanced_accuracy_score(y_test, rnd_test_perds))\n",
    "    rnd_conf_mtx_list.append(confusion_matrix(y_test, rnd_test_perds))\n",
    "\n",
    "# Print out the results\n",
    "for i, max_depth in enumerate(max_depths):\n",
    "    print(f\"Results for max_depth={max_depth}:\")\n",
    "    print(f\"Accuracy score: {rnd_acc_list[i]}\")\n",
    "    print(f\"Balanced accuracy score: {rnd_bal_acc_list[i]}\")\n",
    "    print(f\"Confusion matrix:\\n{rnd_conf_mtx_list[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-western",
   "metadata": {
    "id": "o7xHd_ac3UHY"
   },
   "source": [
    "- Discribe the results of the evaluation. What can be said about the different hyperparameters?\n",
    "\n",
    "\n",
    "    **YOUR SOLUTION COMES HERE...**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-radio",
   "metadata": {
    "id": "structured-alloy"
   },
   "source": [
    "### 5/b. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "spectacular-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-south",
   "metadata": {
    "id": "J9Nkcaws3Xgr"
   },
   "source": [
    "- Train a `MultinomialNB` (Naive Bayes) model on the training set.\n",
    "- Predict with the trained model on the test set and save the prediction into the `nb_test_pred` variable.\n",
    "- Evaluate the results of the classifier with the results of the following functions from the `metrics` module:\n",
    "  - The `accuracy_score` (save the results into the `nb_acc` variable).\n",
    "  - The `balanced_accuracy_score` (save the results into the `nb_bal_acc` varaible).\n",
    "  - The `confusion_matrix` (save the results into the `nb_conf_mtx` variable).\n",
    "- Print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "certain-degree",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cellular-april",
    "outputId": "29914e90-d46f-4917-b2d1-42264b4fc479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:0.8753363228699551\n",
      "Balanced accuracy score: 0.5484998573233868\n",
      "Confusion matrix:\n",
      "[[961   1]\n",
      " [138  15]]\n"
     ]
    }
   ],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "nb_clf=MultinomialNB()\n",
    "\n",
    "nb_clf.fit(x_train,y_train)\n",
    "# predict values\n",
    "nb_test_pred = nb_clf.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "nb_acc = accuracy_score(y_test, nb_test_pred)\n",
    "nb_bal_acc=balanced_accuracy_score(y_test, nb_test_pred)\n",
    "nb_conf_mtx = confusion_matrix(y_test, nb_test_pred)\n",
    "\n",
    "print(f\"Accuracy score:{nb_acc}\")\n",
    "print(f\"Balanced accuracy score: {nb_bal_acc}\")\n",
    "print(f\"Confusion matrix:\\n{nb_conf_mtx}\")\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-thousand",
   "metadata": {
    "id": "timely-caution"
   },
   "source": [
    "### 5/c. LinearModel - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "unknown-parent",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "valid-customs",
    "outputId": "c0f28233-9acd-47bf-af82-0c5a89f63c10"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-defendant",
   "metadata": {
    "id": "J9Nkcaws3Xgr"
   },
   "source": [
    "- Train a `LinearSVC` (Support Vector Classifier) model on the training set.\n",
    "- Predict with the trained model on the test set and save the prediction into the `svm_test_pred` variable.\n",
    "- Evaluate the results of the classifier with the results of the following functions from the `metrics` module:\n",
    "  - The `accuracy_score` (save the results into the `svm_acc` variable).\n",
    "  - The `balanced_accuracy_score` (save the results into the `svm_bal_acc` varaible).\n",
    "  - The `confusion_matrix` (save the results into the `svm_conf_mtx` variable).\n",
    "- Print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "narrative-pearl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cellular-april",
    "outputId": "29914e90-d46f-4917-b2d1-42264b4fc479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:0.8753363228699551\n",
      "Balanced accuracy score: 0.5484998573233868\n",
      "Confusion matrix:\n",
      "[[961   1]\n",
      " [138  15]]\n"
     ]
    }
   ],
   "source": [
    "########################## Implement your solution BELOW ##########################\n",
    "svm_clf=LinearSVC()\n",
    "\n",
    "\n",
    "svm_clf.fit(x_train,y_train)\n",
    "# predict values\n",
    "svm_test_pred = nb_clf.predict(x_test)\n",
    "\n",
    "# Accuracy\n",
    "svm_acc = accuracy_score(y_test, svm_test_pred)\n",
    "svm_bal_acc=balanced_accuracy_score(y_test, svm_test_pred)\n",
    "svm_conf_mtx = confusion_matrix(y_test, svm_test_pred)\n",
    "\n",
    "\n",
    "print(f\"Accuracy score:{svm_acc}\")\n",
    "print(f\"Balanced accuracy score: {svm_bal_acc}\")\n",
    "print(f\"Confusion matrix:\\n{svm_conf_mtx}\")\n",
    "\n",
    "########################## Implement your solution ABOVE ##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-declaration",
   "metadata": {
    "id": "expected-commission"
   },
   "source": [
    "### 5/d Model Comparisons\n",
    "- Discribe the results of the whole evaluation of the 3 different models. What can be said about their performance?\n",
    "\n",
    "\n",
    "Basically, we tried three different models each of them with a different intuition to solve a problem. The Random Forest Classifier this the best model among these three. It has an accuracy score is equal to 0.9802690582959641, and a balanced accuracy score of 0.9397713199144326 with max_depth=20. The remaining two models giving the same strangely gave the same results of 88% accuracy with a 54% balanced accuracy score. There is a significant difference between the balanced accuracy score of RFC and SVM and NB. When there is a significant difference between the balanced accuracy scores of two models on the same data, it indicates that the models are performing differently in terms of their ability to correctly classify each class in a balanced way. Balanced accuracy is a metric that takes into account the distribution of the classes in the data set, and it provides a more accurate assessment of model performance when the classes are imbalanced. A balanced accuracy score of 0.5 indicates that the model is performing no better than random, while a score of 1.0 indicates perfect classification accuracy. If one model has a significantly higher balanced accuracy score than another model on the same data, it means that the former model is better at correctly classifying each class in a balanced way. This could be due to a variety of factors, such as the choice of algorithm, the quality of the features used for classification, or the tuning of hyperparameters. It is important to note that while balanced accuracy is a useful metric for assessing model performance on imbalanced datasets, it should be used in conjunction with other metrics such as precision, recall, and F1-score to get a more complete picture of the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f56ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Szeier Szilvia NLP - Assignment 1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "d1e8c0d757e42bb6dd2d02df6dd6ac3621d4ac94b1d7e71b9ccf65bd0d184b20"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
